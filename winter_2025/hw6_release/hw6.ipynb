{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbW0rQLpuHHX"
      },
      "source": [
        "# Homework 6\n",
        "*This notebook includes both coding and written questions. Please hand in this notebook file with all the outputs and your answers to the written questions.*\n",
        "\n",
        "This assignment covers K-Means and HAC methods for clustering and image segmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wl1C11pFuHHY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(\"CS131_release\"):\n",
        "    # Clone the repository if it doesn't already exist\n",
        "    !git clone https://github.com/StanfordVL/CS131_release.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDiLH4iUuHHZ"
      },
      "outputs": [],
      "source": [
        "%cd CS131_release/winter_2025/hw6_release/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_E4SBhnxuHHZ"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "from __future__ import print_function\n",
        "from time import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from skimage import io\n",
        "from scipy.spatial.distance import squareform, pdist, cdist\n",
        "from skimage.util import img_as_float\n",
        "import os\n",
        "from skimage import transform\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (15.0, 12.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# for auto-reloading extenrnal modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgQNZUftuHHZ"
      },
      "source": [
        "## Introduction\n",
        "In this assignment, you will use clustering algorithms to segment images. You will then use these segmentations to identify foreground and background objects.\n",
        "\n",
        "Your assignment will involve the following subtasks:\n",
        "- **Clustering algorithms**: Implement K-Means clustering and Hierarchical Agglomerative Clustering.\n",
        "- **Pixel-level features**: Implement a feature vector that combines color and position information and implement feature normalization.\n",
        "- **Quantitative Evaluation**: Evaluate segmentation algorithms with a variety of parameter settings by comparing your computed segmentations against a dataset of ground-truth segmentations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZkughbtuHHZ"
      },
      "source": [
        "## 1 Clustering Algorithms (40 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdT1a_reuHHZ"
      },
      "outputs": [],
      "source": [
        "# Generate random data points for clustering\n",
        "\n",
        "# Set seed for consistency\n",
        "np.random.seed(0)\n",
        "\n",
        "# Cluster 1\n",
        "mean1 = [-1, 0]\n",
        "cov1 = [[0.1, 0], [0, 0.1]]\n",
        "X1 = np.random.multivariate_normal(mean1, cov1, 100)\n",
        "\n",
        "# Cluster 2\n",
        "mean2 = [0, 1]\n",
        "cov2 = [[0.1, 0], [0, 0.1]]\n",
        "X2 = np.random.multivariate_normal(mean2, cov2, 100)\n",
        "\n",
        "# Cluster 3\n",
        "mean3 = [1, 0]\n",
        "cov3 = [[0.1, 0], [0, 0.1]]\n",
        "X3 = np.random.multivariate_normal(mean3, cov3, 100)\n",
        "\n",
        "# Cluster 4\n",
        "mean4 = [0, -1]\n",
        "cov4 = [[0.1, 0], [0, 0.1]]\n",
        "X4 = np.random.multivariate_normal(mean4, cov4, 100)\n",
        "\n",
        "# Merge two sets of data points\n",
        "X = np.concatenate((X1, X2, X3, X4))\n",
        "\n",
        "# Plot data points\n",
        "plt.scatter(X[:, 0], X[:, 1])\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqUe3xu-uHHa"
      },
      "source": [
        "### 1.1 K-Means Clustering (20 points)\n",
        "As discussed in class, K-Means is one of the most popular clustering algorithms. We have provided pseudo code for K-Means clustering below. Your first task is to finish implementing **`kmeans`**. This version uses nested for loops to assign points to the closest centroid and compute a new mean for each cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pt-6RoPSuHHa"
      },
      "outputs": [],
      "source": [
        "def kmeans(features, k, num_iters=100):\n",
        "    \"\"\" Use kmeans algorithm to group features into k clusters.\n",
        "\n",
        "    K-Means algorithm can be broken down into following steps:\n",
        "        1. Randomly initialize cluster centers\n",
        "        2. Assign each point to the closest center\n",
        "        3. Compute new center of each cluster\n",
        "        4. Stop if cluster assignments did not change\n",
        "        5. Go to step 2\n",
        "\n",
        "    Args:\n",
        "        features - Array of N features vectors. Each row represents a feature\n",
        "            vector.\n",
        "        k - Number of clusters to form.\n",
        "        num_iters - Maximum number of iterations the algorithm will run.\n",
        "\n",
        "    Returns:\n",
        "        assignments - Array representing cluster assignment of each point.\n",
        "            (e.g. i-th point is assigned to cluster assignments[i])\n",
        "    \"\"\"\n",
        "\n",
        "    N, D = features.shape\n",
        "\n",
        "    assert N >= k, 'Number of clusters cannot be greater than number of points'\n",
        "\n",
        "    # Randomly initalize cluster centers\n",
        "    idxs = np.random.choice(N, size=k, replace=False)\n",
        "    centers = features[idxs]\n",
        "    assignments = np.zeros(N, dtype=np.uint32)\n",
        "\n",
        "    for n in range(num_iters):\n",
        "        ### YOUR CODE HERE\n",
        "       pass\n",
        "        ### END YOUR CODE\n",
        "\n",
        "    return assignments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9SRL2WKuHHa"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "start = time()\n",
        "assignments = kmeans(X, 4)\n",
        "end = time()\n",
        "\n",
        "kmeans_runtime = end - start\n",
        "\n",
        "print(\"kmeans running time: %f seconds.\" % kmeans_runtime)\n",
        "\n",
        "for i in range(4):\n",
        "    cluster_i = X[assignments==i]\n",
        "    plt.scatter(cluster_i[:, 0], cluster_i[:, 1])\n",
        "\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDEJ6vUSuHHa"
      },
      "source": [
        "We can use numpy functions and broadcasting to make K-Means faster. Implement **`kmeans_fast`**. This should run at least 10 times faster than the previous implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbOucVGXuHHa"
      },
      "outputs": [],
      "source": [
        "def kmeans_fast(features, k, num_iters=100):\n",
        "    \"\"\" Use kmeans algorithm to group features into k clusters.\n",
        "\n",
        "    This function makes use of numpy functions and broadcasting to speed up the\n",
        "    first part(cluster assignment) of kmeans algorithm.\n",
        "\n",
        "    Hints\n",
        "    - You may find cdist (imported from scipy.spatial.distance) and np.argmin useful\n",
        "\n",
        "    Args:\n",
        "        features - Array of N features vectors. Each row represents a feature\n",
        "            vector.\n",
        "        k - Number of clusters to form.\n",
        "        num_iters - Maximum number of iterations the algorithm will run.\n",
        "\n",
        "    Returns:\n",
        "        assignments - Array representing cluster assignment of each point.\n",
        "            (e.g. i-th point is assigned to cluster assignments[i])\n",
        "    \"\"\"\n",
        "\n",
        "    N, D = features.shape\n",
        "\n",
        "    assert N >= k, 'Number of clusters cannot be greater than number of points'\n",
        "\n",
        "    # Randomly initalize cluster centers\n",
        "    idxs = np.random.choice(N, size=k, replace=False)\n",
        "    centers = features[idxs]\n",
        "    assignments = np.zeros(N, dtype=np.uint32)\n",
        "\n",
        "    for n in range(num_iters):\n",
        "        ### YOUR CODE HERE\n",
        "        pass\n",
        "        ### END YOUR CODE\n",
        "\n",
        "    return assignments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLNkFloUuHHa"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "start = time()\n",
        "assignments = kmeans_fast(X, 4)\n",
        "end = time()\n",
        "\n",
        "kmeans_fast_runtime = end - start\n",
        "print(\"kmeans running time: %f seconds.\" % kmeans_fast_runtime)\n",
        "print(\"%f times faster!\" % (kmeans_runtime / kmeans_fast_runtime))\n",
        "\n",
        "for i in range(4):\n",
        "    cluster_i = X[assignments==i]\n",
        "    plt.scatter(cluster_i[:, 0], cluster_i[:, 1])\n",
        "\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rPxUQ8kuHHa"
      },
      "source": [
        "### 1.2 K-Means Convergence (10 points)\n",
        "Implementations of the K-Means algorithm will often have the parameter `num_iters` to define the maximum number of iterations the algorithm should run for. Consider that we opt to not include this upper bound on the number of iterations, and that we define the termination criterion of the algorithm to be when the cost $L$ stops changing.\n",
        "\n",
        "Recall that $L$ is defined as the sum of squared distance between all points $x$ and their nearest cluster center $c$:\n",
        "\n",
        "$$L = \\sum_{i \\in clusters}\\sum_{x \\in cluster_i} (x - c_i)^2$$\n",
        "\n",
        "Show that for any set of points **$D$** and any number of clusters $k$, the K-Means algorithm will terminate in a finite number of iterations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNPlFyOQuHHa"
      },
      "source": [
        "**Your answer here:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo1s26GwuHHa"
      },
      "source": [
        "### 1.3 Hierarchical Agglomerative Clustering (10 points)\n",
        "Another simple clustering algorithm is Hieararchical Agglomerative Clustering, which is somtimes abbreviated as HAC. In this algorithm, each point is initially assigned to its own cluster. Then cluster pairs are merged until we are left with the desired number of predetermined clusters (see Algorithm 1).\n",
        "\n",
        "Implement **`hiererachical_clustering`**.\n",
        "\n",
        "<!-- ![algo1.png](attachment:algo1.png) -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxzAp6ChuHHb"
      },
      "outputs": [],
      "source": [
        "def hierarchical_clustering(features, k):\n",
        "    \"\"\" Run the hierarchical agglomerative clustering algorithm.\n",
        "\n",
        "    The algorithm is conceptually simple:\n",
        "\n",
        "    Assign each point to its own cluster\n",
        "    While the number of clusters is greater than k:\n",
        "        Compute the distance between all pairs of clusters\n",
        "        Merge the pair of clusters that are closest to each other\n",
        "\n",
        "    We will use Euclidean distance to define distance between clusters.\n",
        "\n",
        "    Recomputing the centroids of all clusters and the distances between all\n",
        "    pairs of centroids at each step of the loop would be very slow. Thankfully\n",
        "    most of the distances and centroids remain the same in successive\n",
        "    iterations of the outer loop; therefore we can speed up the computation by\n",
        "    only recomputing the centroid and distances for the new merged cluster.\n",
        "\n",
        "    Even with this trick, this algorithm will consume a lot of memory and run\n",
        "    very slowly when clustering large set of points. In practice, you probably\n",
        "    do not want to use this algorithm to cluster more than 10,000 points.\n",
        "\n",
        "    Hints\n",
        "    - You may find pdist (imported from scipy.spatial.distance) useful\n",
        "\n",
        "    Args:\n",
        "        features - Array of N features vectors. Each row represents a feature\n",
        "            vector.\n",
        "        k - Number of clusters to form.\n",
        "\n",
        "    Returns:\n",
        "        assignments - Array representing cluster assignment of each point.\n",
        "            (e.g. i-th point is assigned to cluster assignments[i])\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    N, D = features.shape\n",
        "\n",
        "    assert N >= k, 'Number of clusters cannot be greater than number of points'\n",
        "\n",
        "    # Assign each point to its own cluster\n",
        "    assignments = np.arange(N, dtype=np.uint32)\n",
        "    centers = np.copy(features)\n",
        "    n_clusters = N\n",
        "\n",
        "    # Initial distances array\n",
        "    dists = squareform(pdist(centers))\n",
        "    np.fill_diagonal(dists, float('inf'))\n",
        "    assert dists.shape == (N, N)\n",
        "\n",
        "    while n_clusters > k:\n",
        "        ### YOUR CODE HERE\n",
        "        pass\n",
        "        ### END YOUR CODE\n",
        "\n",
        "    return assignments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-oq_Mo1uHHb"
      },
      "outputs": [],
      "source": [
        "start = time()\n",
        "assignments = hierarchical_clustering(X, 4)\n",
        "end = time()\n",
        "\n",
        "print(\"hierarchical_clustering running time: %f seconds.\" % (end - start))\n",
        "\n",
        "for i in range(4):\n",
        "    cluster_i = X[assignments==i]\n",
        "    plt.scatter(cluster_i[:, 0], cluster_i[:, 1])\n",
        "\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP_5Fa5puHHb"
      },
      "source": [
        "## 2 Pixel-Level Features (30 points)\n",
        "Before we can use a clustering algorithm to segment an image, we must compute some *feature vector* for each pixel. The feature vector for each pixel should encode the qualities that we care about in a good segmentation. More concretely, for a pair of pixels $p_i$ and $p_j$ with corresponding feature vectors $f_i$ and $f_j$, the distance between $f_i$ and $f_j$ should be small if we believe that $p_i$ and $p_j$ should be placed in the same segment and large otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_f_BhWhuHHb"
      },
      "outputs": [],
      "source": [
        "# Load and display image\n",
        "img = io.imread('train.jpg')\n",
        "H, W, C = img.shape\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p39W7uG5uHHb"
      },
      "source": [
        "### 2.1 Color Features (15 points)\n",
        "One of the simplest possible feature vectors for a pixel is simply the vector of colors for that pixel. Implement **`color_features`**. Output should look like the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KO0SvMuuHHb"
      },
      "outputs": [],
      "source": [
        "plt.imshow(io.imread('color_features.png'))\n",
        "plt.title('Segmentation Solution')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVu60tDmuHHb"
      },
      "outputs": [],
      "source": [
        "### Pixel-Level Features\n",
        "def color_features(img):\n",
        "    \"\"\" Represents a pixel by its color.\n",
        "\n",
        "    Args:\n",
        "        img - array of shape (H, W, C)\n",
        "\n",
        "    Returns:\n",
        "        features - array of (H * W, C)\n",
        "    \"\"\"\n",
        "    H, W, C = img.shape\n",
        "    img = img_as_float(img)\n",
        "    features = np.zeros((H*W, C))\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "    pass\n",
        "    ### END YOUR CODE\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7bCffWTuHHb"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "features = color_features(img)\n",
        "\n",
        "# Sanity checks\n",
        "assert features.shape == (H * W, C),\\\n",
        "    \"Incorrect shape! Check your implementation.\"\n",
        "\n",
        "assert features.dtype == float,\\\n",
        "    \"dtype of color_features should be float.\"\n",
        "\n",
        "assignments = kmeans_fast(features, 8)\n",
        "segments = assignments.reshape((H, W))\n",
        "\n",
        "# Display segmentation\n",
        "plt.imshow(segments, cmap='viridis')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cN2Dws6uHHb"
      },
      "source": [
        "In the cell below, we visualize each segment as the mean color of pixels in the segment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofNhPFtTuHHb"
      },
      "outputs": [],
      "source": [
        "def visualize_mean_color_image(img, segments):\n",
        "\n",
        "    img = img_as_float(img)\n",
        "    k = np.max(segments) + 1\n",
        "    mean_color_img = np.zeros(img.shape)\n",
        "\n",
        "    for i in range(k):\n",
        "        mean_color = np.mean(img[segments == i], axis=0)\n",
        "        mean_color_img[segments == i] = mean_color\n",
        "\n",
        "    plt.imshow(mean_color_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qc5Tx17EuHHb"
      },
      "outputs": [],
      "source": [
        "visualize_mean_color_image(img, segments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RHO1b3suHHb"
      },
      "source": [
        "### 2.2 Color and Position Features (15 points)\n",
        "Another simple feature vector for a pixel is to concatenate its color and position within the image. In other words, for a pixel of color $(r, g, b)$ located at position $(x, y)$ in the image, its feature vector would be $(r, g, b, x, y)$. However, the color and position features may have drastically different ranges; for example each color channel of an image may be in the range $[0, 1)$, while the position of each pixel may have a much wider range. Uneven scaling between different features in the feature vector may cause clustering algorithms to behave poorly.\n",
        "\n",
        "One way to correct for uneven scaling between different features is to apply some sort of normalization to the feature vector. One of the simplest types of normalization is to force each feature to have zero mean and unit variance.\n",
        "\n",
        "Implement **`color_position_features`**.\n",
        "\n",
        "Output segmentation should look like the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPUeHw2xuHHb"
      },
      "outputs": [],
      "source": [
        "plt.imshow(io.imread('color_position_features.png'))\n",
        "plt.title('Segmentation Solution')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lYiKmU-uHHb"
      },
      "outputs": [],
      "source": [
        "def color_position_features(img):\n",
        "    \"\"\" Represents a pixel by its color and position.\n",
        "\n",
        "    Combine pixel's RGB value and xy coordinates into a feature vector.\n",
        "    i.e. for a pixel of color (r, g, b) located at position (x, y) in the\n",
        "    image. its feature vector would be (r, g, b, x, y).\n",
        "\n",
        "    Don't forget to normalize features.\n",
        "\n",
        "    Hints\n",
        "    - You may find np.mgrid and np.dstack useful\n",
        "    - You may use np.mean and np.std\n",
        "\n",
        "    Args:\n",
        "        img - array of shape (H, W, C)\n",
        "\n",
        "    Returns:\n",
        "        features - array of (H * W, C+2)\n",
        "    \"\"\"\n",
        "    H, W, C = img.shape\n",
        "    color = img_as_float(img)\n",
        "    features = np.zeros((H*W, C+2))\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "    pass\n",
        "    ### END YOUR CODE\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bD0NKM4_uHHb"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "features = color_position_features(img)\n",
        "\n",
        "# Sanity checks\n",
        "assert features.shape == (H * W, C + 2),\\\n",
        "    \"Incorrect shape! Check your implementation.\"\n",
        "\n",
        "assert features.dtype == float,\\\n",
        "    \"dtype of color_features should be float.\"\n",
        "\n",
        "assignments = kmeans_fast(features, 8)\n",
        "segments = assignments.reshape((H, W))\n",
        "\n",
        "# Display segmentation\n",
        "plt.imshow(segments, cmap='viridis')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Uj92kgfuHHb"
      },
      "outputs": [],
      "source": [
        "visualize_mean_color_image(img, segments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5VlmNKQuHHb"
      },
      "source": [
        "### Extra Credit: Implement Your Own Feature\n",
        "For this programming assignment we have asked you to implement a very simple feature transform for each pixel. While it is not required, you should feel free to experiment with other feature transforms. Could your final segmentations be improved by adding gradients, edges, SIFT descriptors, or other information to your feature vectors? Could a different type of normalization give better results?\n",
        "\n",
        "Implement your feature extractor **`my_features`**.\n",
        "\n",
        "Depending on the creativity of your approach and the quality of your writeup, implementing extra feature vectors can be worth extra credit (up to 1% of final grade)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HDSYuA7uHHb"
      },
      "source": [
        "**Describe your approach**: (YOUR APPROACH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eu1HElAHuHHc"
      },
      "outputs": [],
      "source": [
        "\n",
        "def my_features(img):\n",
        "    \"\"\" Implement your own features\n",
        "\n",
        "    Args:\n",
        "        img - array of shape (H, W, C)\n",
        "\n",
        "    Returns:\n",
        "        features - array of (H * W, C)\n",
        "    \"\"\"\n",
        "    features = None\n",
        "    ### YOUR CODE HERE\n",
        "    pass\n",
        "    ### END YOUR CODE\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHN1LTLKuHHc"
      },
      "outputs": [],
      "source": [
        "# Feel free to experiment with different images\n",
        "# and varying number of segments\n",
        "img = io.imread('train.jpg')\n",
        "num_segments = 8\n",
        "\n",
        "H, W, C = img.shape\n",
        "\n",
        "# Extract pixel-level features\n",
        "features = my_features(img)\n",
        "\n",
        "# Run clustering algorithm\n",
        "assignments = kmeans_fast(features, num_segments)\n",
        "\n",
        "segments = assignments.reshape((H, W))\n",
        "\n",
        "# Display segmentation\n",
        "plt.imshow(segments, cmap='viridis')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_m3nc6tuHHc"
      },
      "source": [
        "## 3 Quantitative Evaluation (30 points)\n",
        "\n",
        "Looking at images is a good way to get an idea for how well an algorithm is working, but the best way to evaluate an algorithm is to have some quantitative measure of its performance.\n",
        "\n",
        "For this project we have supplied a small dataset of cat images and ground truth segmentations of these images into foreground (cats) and background (everything else). We will quantitatively evaluate different segmentation methods (features and clustering methods) on this dataset.\n",
        "\n",
        "We can cast the segmentation task into a binary classification problem, where we need to classify each pixel in an image into either foreground (positive) or background (negative). Given the ground-truth labels, the accuracy of a segmentation is $(TP+TN)/(P+N)$.\n",
        "\n",
        "Implement **`compute_accuracy`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHUyqD1ouHHc"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(mask_gt, mask):\n",
        "    \"\"\" Compute the pixel-wise accuracy of a foreground-background segmentation\n",
        "        given a ground truth segmentation.\n",
        "\n",
        "    Args:\n",
        "        mask_gt - The ground truth foreground-background segmentation. A\n",
        "            logical of size H x W where mask_gt[y, x] is 1 if and only if\n",
        "            pixel (y, x) of the original image was part of the foreground.\n",
        "        mask - The estimated foreground-background segmentation. A logical\n",
        "            array of the same size and format as mask_gt.\n",
        "\n",
        "    Returns:\n",
        "        accuracy - The fraction of pixels where mask_gt and mask agree. A\n",
        "            bigger number is better, where 1.0 indicates a perfect segmentation.\n",
        "    \"\"\"\n",
        "\n",
        "    accuracy = None\n",
        "    ### YOUR CODE HERE\n",
        "    pass\n",
        "    ### END YOUR CODE\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIa5SSymuHHc"
      },
      "outputs": [],
      "source": [
        "mask_gt = np.zeros((100, 100))\n",
        "mask = np.zeros((100, 100))\n",
        "\n",
        "# Test compute_accracy function\n",
        "mask_gt[20:50, 30:60] = 1\n",
        "mask[30:50, 30:60] = 1\n",
        "\n",
        "accuracy = compute_accuracy(mask_gt, mask)\n",
        "\n",
        "print('Accuracy: %0.2f' % (accuracy))\n",
        "if accuracy != 0.97:\n",
        "    print('Check your implementation!')\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.imshow(mask_gt)\n",
        "plt.title('Ground Truth')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.imshow(mask)\n",
        "plt.title('Estimate')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9SSVzM9uHHc"
      },
      "source": [
        "You can use the script below to evaluate a segmentation methodâ€™s ability to separate foreground from background on the entire provided dataset. Use this script as a starting point to evaluate a variety of segmentation parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLanmQUCuHHc"
      },
      "outputs": [],
      "source": [
        "def evaluate_segmentation(mask_gt, segments):\n",
        "    \"\"\" Compare the estimated segmentation with the ground truth.\n",
        "\n",
        "    Note that 'mask_gt' is a binary mask, while 'segments' contain k segments.\n",
        "    This function compares each segment in 'segments' with the ground truth and\n",
        "    outputs the accuracy of the best segment.\n",
        "\n",
        "    Args:\n",
        "        mask_gt - The ground truth foreground-background segmentation. A\n",
        "            logical of size H x W where mask_gt[y, x] is 1 if and only if\n",
        "            pixel (y, x) of the original image was part of the foreground.\n",
        "        segments - An array of the same size as mask_gt. The value of a pixel\n",
        "            indicates the segment it belongs.\n",
        "\n",
        "    Returns:\n",
        "        best_accuracy - Accuracy of the best performing segment.\n",
        "            0 <= accuracy <= 1, where 1.0 indicates a perfect segmentation.\n",
        "    \"\"\"\n",
        "\n",
        "    num_segments = np.max(segments) + 1\n",
        "    best_accuracy = 0\n",
        "\n",
        "    # Compare each segment in 'segments' with the ground truth\n",
        "    for i in range(num_segments):\n",
        "        mask = (segments == i).astype(int)\n",
        "        accuracy = compute_accuracy(mask_gt, mask)\n",
        "        best_accuracy = max(accuracy, best_accuracy)\n",
        "\n",
        "    return best_accuracy\n",
        "\n",
        "def load_dataset(data_dir):\n",
        "    \"\"\"\n",
        "    This function assumes 'gt' directory contains ground truth segmentation\n",
        "    masks for images in 'imgs' dir. The segmentation mask for image\n",
        "    'imgs/aaa.jpg' is 'gt/aaa.png'\n",
        "    \"\"\"\n",
        "\n",
        "    imgs = []\n",
        "    gt_masks = []\n",
        "\n",
        "    # Load all the images under 'data_dir/imgs' and corresponding\n",
        "    # segmentation masks under 'data_dir/gt'.\n",
        "    for fname in sorted(os.listdir(os.path.join(data_dir, 'imgs'))):\n",
        "        if fname.endswith('.jpg'):\n",
        "            # Load image\n",
        "            img = io.imread(os.path.join(data_dir, 'imgs', fname))\n",
        "            imgs.append(img)\n",
        "\n",
        "            # Load corresponding gt segmentation mask\n",
        "            mask_fname = fname[:-4] + '.png'\n",
        "            gt_mask = io.imread(os.path.join(data_dir, 'gt', mask_fname))\n",
        "            gt_mask = (gt_mask != 0).astype(int) # Convert to binary mask (0s and 1s)\n",
        "            gt_masks.append(gt_mask)\n",
        "\n",
        "    return imgs, gt_masks\n",
        "\n",
        "def compute_segmentation(img, k,\n",
        "        clustering_fn=kmeans_fast,\n",
        "        feature_fn=color_position_features,\n",
        "        scale=0):\n",
        "    \"\"\" Compute a segmentation for an image.\n",
        "\n",
        "    First a feature vector is extracted from each pixel of an image. Next a\n",
        "    clustering algorithm is applied to the set of all feature vectors. Two\n",
        "    pixels are assigned to the same segment if and only if their feature\n",
        "    vectors are assigned to the same cluster.\n",
        "\n",
        "    Args:\n",
        "        img - An array of shape (H, W, C) to segment.\n",
        "        k - The number of segments into which the image should be split.\n",
        "        clustering_fn - The method to use for clustering. The function should\n",
        "            take an array of N points and an integer value k as input and\n",
        "            output an array of N assignments.\n",
        "        feature_fn - A function used to extract features from the image.\n",
        "        scale - (OPTIONAL) parameter giving the scale to which the image\n",
        "            should be in the range 0 < scale <= 1. Setting this argument to a\n",
        "            smaller value will increase the speed of the clustering algorithm\n",
        "            but will cause computed segments to be blockier. This setting is\n",
        "            usually not necessary for kmeans clustering, but when using HAC\n",
        "            clustering this parameter will probably need to be set to a value\n",
        "            less than 1.\n",
        "    \"\"\"\n",
        "\n",
        "    assert scale <= 1 and scale >= 0, \\\n",
        "        'Scale should be in the range between 0 and 1'\n",
        "\n",
        "    H, W, C = img.shape\n",
        "\n",
        "    if scale > 0:\n",
        "        # Scale down the image for faster computation.\n",
        "        img = transform.rescale(img, scale)\n",
        "\n",
        "    features = feature_fn(img)\n",
        "    assignments = clustering_fn(features, k)\n",
        "    segments = assignments.reshape((img.shape[:2]))\n",
        "\n",
        "    if scale > 0:\n",
        "        # Resize segmentation back to the image's original size\n",
        "        segments = transform.resize(segments, (H, W), preserve_range=True)\n",
        "\n",
        "        # Resizing results in non-interger values of pixels.\n",
        "        # Round pixel values to the closest interger\n",
        "        segments = np.rint(segments).astype(int)\n",
        "\n",
        "    return segments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YmFbg6UuHHc"
      },
      "outputs": [],
      "source": [
        "# Load a small segmentation dataset\n",
        "imgs, gt_masks = load_dataset('./data')\n",
        "\n",
        "# Set the parameters for segmentation.\n",
        "num_segments = 3\n",
        "clustering_fn = kmeans_fast\n",
        "feature_fn = color_features\n",
        "scale = 0.5\n",
        "\n",
        "mean_accuracy = 0.0\n",
        "\n",
        "segmentations = []\n",
        "\n",
        "for i, (img, gt_mask) in enumerate(zip(imgs, gt_masks)):\n",
        "    # Compute a segmentation for this image\n",
        "    segments = compute_segmentation(img, num_segments,\n",
        "                                    clustering_fn=clustering_fn,\n",
        "                                    feature_fn=feature_fn,\n",
        "                                    scale=scale)\n",
        "\n",
        "    segmentations.append(segments)\n",
        "\n",
        "    # Evaluate segmentation\n",
        "    accuracy = evaluate_segmentation(gt_mask, segments)\n",
        "\n",
        "    print('Accuracy for image %d: %0.4f' %(i, accuracy))\n",
        "    mean_accuracy += accuracy\n",
        "\n",
        "mean_accuracy = mean_accuracy / len(imgs)\n",
        "print('Mean accuracy: %0.4f' % mean_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "y7ciE4yiuHHd"
      },
      "outputs": [],
      "source": [
        "# Visualize segmentation results\n",
        "\n",
        "N = len(imgs)\n",
        "plt.figure(figsize=(15,60))\n",
        "for i in range(N):\n",
        "\n",
        "    plt.subplot(N, 3, (i * 3) + 1)\n",
        "    plt.imshow(imgs[i])\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(N, 3, (i * 3) + 2)\n",
        "    plt.imshow(gt_masks[i])\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(N, 3, (i * 3) + 3)\n",
        "    plt.imshow(segmentations[i], cmap='viridis')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugKNDFIpuHHd"
      },
      "source": [
        "Include a detailed evaluation of the effect of varying segmentation parameters (feature transform, clustering method, number of clusters, resize) on the mean accuracy of foreground-background segmentations on the provided dataset. You should test a minimum of 6 combinations of parameters. To present your results, add rows to the table below (you may delete the first row).\n",
        "\n",
        "**One tip from us** is that it's okay to avoid using hierarchical clustering altogether. The HAC algorithm is quite slow for larger scales. It is totally fine to just K-Means and modulate the other parameters of the clustering function!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "wj1C2qjJuHHd"
      },
      "source": [
        " <table style=\"width:100%\">\n",
        "  <tr>\n",
        "    <th>Feature Transform</th>\n",
        "    <th>Clustering Method</th>\n",
        "    <th>Number of segments</th>\n",
        "    <th>Scale</th>\n",
        "    <th>Mean Accuracy</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Color</td>\n",
        "    <td>K-Means</td>\n",
        "    <td>3</td>\n",
        "    <td>0.5</td>\n",
        "    <td>0.58</td>\n",
        "  </tr>\n",
        "   <tr>\n",
        "    <td>...</td>\n",
        "    <td>...</td>\n",
        "    <td>...</td>\n",
        "    <td>...</td>\n",
        "    <td>...</td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQcla2cuuHHd"
      },
      "source": [
        "Observe your results carefully and try to answer the following question:\n",
        "1. Based on your quantitative experiments, how do each of the segmentation parameters affect the quality of the final foreground-background segmentation?\n",
        "2. Are some images simply more difficult to segment correctly than others? If so, what are the qualities of these images that cause the segmentation algorithms to perform poorly?\n",
        "3. Also feel free to point out or discuss any other interesting observations that you made.\n",
        "\n",
        "Write your analysis in the cell below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AliibrPYuHHd"
      },
      "source": [
        "**Your answer here**:"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}